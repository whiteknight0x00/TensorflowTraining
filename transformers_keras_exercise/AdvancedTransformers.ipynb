{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab: Building Advanced Transformers\n",
    "Estimated time needed: 30 minutes\n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras.\n",
    "\n",
    "Learning objectives:\n",
    "\n",
    "By the end of this lab, you will:\n",
    "\n",
    "Implement advanced Transformer models using Keras.\n",
    "\n",
    "Apply Transformers to real-world sequential data tasks.\n",
    "\n",
    "Build, train, and evaluate Transformer models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step-by-Step Instructions:\n",
    "Step 1: Import necessary libraries\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as tensorflow.keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_price.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.api.layers import Layer, Dense, LayerNormalization, Dropout\n",
    "from keras.api.models import Sequential, Model\n",
    "\n",
    "#  Setup the Environment to generate synthetic stock price data\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_price.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_price.csv', index=False)\n",
    "print(\"Synthetic stock_price.csv created and loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (1899, 100, 1)\n",
      "Shape of Y:  (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('stock_price.csv')\n",
    "data = data[['Close']].values\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X: \", X.shape)\n",
    "print(\"Shape of Y: \", Y.shape)\n",
    "\n",
    "# In the above code:\n",
    "# tensorflow is the main library for machine learning in Python.\n",
    "# stock_prices.csv is the data set that is loaded.\n",
    "# MinMaxScaler method is used to normalize the data.\n",
    "# create_datasetmethod is used to prepare the data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Implement Multi-Head Self-Attention\n",
    "# Define the Multi-Head Self-Attention mechanism.\n",
    "# define the class\n",
    "class MultiHeadSelfAttention(Layer):\n",
    "    # initialize the class\n",
    "    # constructor\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        # call the parent class constructor\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        # assign the parameters\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = Dense(embed_dim)\n",
    "        self.key_dense = Dense(embed_dim)\n",
    "        self.value_dense = Dense(embed_dim)\n",
    "        self.combine_heads = Dense(embed_dim)\n",
    "\n",
    "    # define the attention mechanism\n",
    "    def attention(self, query, key, value):\n",
    "        # compute the score\n",
    "        # \"\"\"Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
    "\n",
    "        #   The inputs must, following any transpositions, be tensors of rank >= 2\n",
    "        #   where the inner 2 dimensions specify valid matrix multiplication dimensions,\n",
    "        #   and any further outer dimensions specify matching batch size.\n",
    "\n",
    "        #   Both matrices must be of the same type. The supported types are:\n",
    "        #   `bfloat16`, `float16`, `float32`, `float64`, `int32`, `int64`,\n",
    "        #   `complex64`, `complex128`.\n",
    "\n",
    "        #   Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
    "        #   the fly by setting one of the corresponding flag to `True`. These are `False`\n",
    "        #   by default.\n",
    "\n",
    "        #   If one or both of the matrices contain a lot of zeros, a more efficient\n",
    "        #   multiplication algorithm can be used by setting the corresponding\n",
    "        #   `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
    "        #   This optimization is only available for plain matrices (rank-2 tensors) with\n",
    "        #   datatypes `bfloat16` or `float32`.\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        # the funney thing is that I thought that TOP⬆️ developers won't use TODOs in their code cuz I think they may be more professional\n",
    "        # LOL NO OFFENSE\n",
    "        '''# pylint: disable=redefined-builtin\n",
    "        # TODO(b/274626120) Update `tf_shape_default_int64` comment when it is better\n",
    "        # supported.\n",
    "        \"\"\"Returns a tensor containing the shape of the input tensor.\n",
    "\n",
    "        See also `tf.size`, `tf.rank`.\n",
    "\n",
    "        `tf.shape` returns a 1-D integer tensor representing the shape of `input`.\n",
    "        For a scalar input, the tensor returned has a shape of (0,) and its value is\n",
    "        the empty vector (i.e. []).\n",
    "\n",
    "        For example:\n",
    "\n",
    "        >>> tf.shape(1.)\n",
    "        <tf.Tensor: shape=(0,), dtype=int32, numpy=array([], dtype=int32)>\n",
    "\n",
    "        >>> t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\n",
    "        >>> tf.shape(t)\n",
    "        <tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 2, 3], dtype=int32)>\n",
    "\n",
    "        Note: When using symbolic tensors, such as when using the Keras API,\n",
    "        tf.shape() will return the shape of the symbolic tensor.\n",
    "\n",
    "        >>> a = tf.keras.layers.Input((None, 10))\n",
    "        >>> tf.shape(a)\n",
    "        <... shape=(3,) dtype=int32...>\n",
    "\n",
    "        In these cases, using `tf.Tensor.shape` will return more informative results.\n",
    "\n",
    "        >>> a.shape\n",
    "        TensorShape([None, None, 10])\n",
    "\n",
    "        (The first `None` represents the as yet unknown batch size.)\n",
    "\n",
    "        `tf.shape` and `Tensor.shape` should be identical in eager mode.  Within\n",
    "        `tf.function` or within a `compat.v1` context, not all dimensions may be\n",
    "        known until execution time. Hence, when defining custom layers and models\n",
    "        for graph mode, prefer the dynamic `tf.shape(x)` over the static `x.shape`.\n",
    "\n",
    "        Args:\n",
    "            input: A `Tensor` or `SparseTensor`.\n",
    "            out_type: (Optional) The specified output type of the operation (`int32` or\n",
    "            `int64`). Defaults to `tf.int32`. (Note: there is an experimental\n",
    "            flag, `tf_shape_default_int64` that changes the default to `tf.int64`.\n",
    "            This is an unsupported, experimental setting that causes known breakages.)\n",
    "            name: A name for the operation (optional).\n",
    "\n",
    "        Returns:\n",
    "            A `Tensor` of type `out_type`.'''\n",
    "        '''  \"\"\"Casts a tensor to a new type.\n",
    "        '''\n",
    "        # --------------------------------------------------------------------------\n",
    "        '''\n",
    "        The operation casts `x` (in case of `Tensor`) or `x.values`\n",
    "        (in case of `SparseTensor` or `IndexedSlices`) to `dtype`.\n",
    "\n",
    "        For example:\n",
    "\n",
    "        >>> x = tf.constant([1.8, 2.2], dtype=tf.float32)\n",
    "        >>> tf.cast(x, tf.int32)\n",
    "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n",
    "\n",
    "        Notice `tf.cast` has an alias `tf.dtypes.cast`:\n",
    "\n",
    "        >>> x = tf.constant([1.8, 2.2], dtype=tf.float32)\n",
    "        >>> tf.dtypes.cast(x, tf.int32)\n",
    "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n",
    "\n",
    "        The operation supports data types (for `x` and `dtype`) of\n",
    "        `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `int32`, `int64`,\n",
    "        `float16`, `float32`, `float64`, `complex64`, `complex128`, `bfloat16`.\n",
    "        In case of casting from complex types (`complex64`, `complex128`) to real\n",
    "        types, only the real part of `x` is returned. In case of casting from real\n",
    "        types to complex types (`complex64`, `complex128`), the imaginary part of the\n",
    "        returned value is set to `0`. The handling of complex types here matches the\n",
    "        behavior of numpy.\n",
    "\n",
    "        Note casting nan and inf values to integral types has undefined behavior.\n",
    "\n",
    "        Note this operation can lead to a loss of precision when converting native\n",
    "        Python `float` and `complex` variables to `tf.float64` or `tf.complex128`\n",
    "        tensors, since the input is first converted to the `float32` data type and\n",
    "        then widened. It is recommended to use `tf.convert_to_tensor` instead of\n",
    "        `tf.cast` for any non-tensor inputs.\n",
    "          Args:\n",
    "        x: A `Tensor` or `SparseTensor` or `IndexedSlices` of numeric type. It could\n",
    "        be `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `int32`,\n",
    "        `int64`, `float16`, `float32`, `float64`, `complex64`, `complex128`,\n",
    "        `bfloat16`.\n",
    "        dtype: The destination type. The list of supported dtypes is the same as\n",
    "        `x`.\n",
    "        name: A name for the operation (optional).\n",
    "\n",
    "        Returns:\n",
    "            A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` and\n",
    "            same type as `dtype`.\n",
    "\n",
    "        Raises:\n",
    "            TypeError: If `x` cannot be cast to the `dtype`.\n",
    "        '''\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "    \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "        attention, _ = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output\n",
    "\n",
    "# In the above code:\n",
    "# The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, \n",
    "#   which allows the model to focus on different parts of the input sequence simultaneously.\n",
    "# The attention parameter computes the attention scores and weighted sum of the values.\n",
    "# The split_heads parameter splits the input into multiple heads for parallel attention computation.\n",
    "# The call method applies the self-attention mechanism and combines the heads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Implement Transformer block<br/>\n",
    "Define the Transformer block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = Sequential([\n",
    "            Dense(ff_dim, activation='relu'),\n",
    "            Dense(embed_dim),\n",
    "        ])\n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    # In the above code:\n",
    "    # The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.\n",
    "    # Dropout is used to prevent overfitting.\n",
    "    # The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n",
    "    #\n",
    "    # I think this is the main part of the transformer model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Implement Encoder Layer<br/>\n",
    "Define the Encoder layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn the above code:\\n\\nThe EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture.\\n\\nIt consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network.\\n\\nBoth sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer.\\n\\nThe call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderLayer(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = Sequential([\n",
    "            Dense(ff_dim, activation='relu'),\n",
    "            Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "'''\n",
    "In the above code:\n",
    "\n",
    "The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture.\n",
    "\n",
    "It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network.\n",
    "\n",
    "Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer.\n",
    "\n",
    "The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Implement Transformer encoder<br/>\n",
    "Define the Transformer Encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 20:17:46.391641: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Max\n",
      "2025-03-14 20:17:46.391778: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 128.00 GB\n",
      "2025-03-14 20:17:46.391788: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 48.00 GB\n",
      "2025-03-14 20:17:46.392291: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-03-14 20:17:46.392316: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nIn the above code:\\n\\nThe TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "    \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) \n",
    "\n",
    "'''\n",
    "In the above code:\n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nIn the above code:\\nThe Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.\\nThe model is then compiled with the Adam optimizer and mean squared error loss.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Step 6: Build and Compile the Transformer model\n",
    "Integrate the Transformer Encoder into a complete model for sequential data.\n",
    "'''\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "'''\n",
    "In the above code:\n",
    "The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.\n",
    "The model is then compiled with the Adam optimizer and mean squared error loss.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 20:17:49.893832: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - loss: 12.5749\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 0.2497\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.2362\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.2095\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.2449\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.1706\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.1779\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - loss: 0.1633\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - loss: 0.1579\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - loss: 0.1549\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.1525\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.1133\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.1116\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.0967\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0862\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0883\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0768\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 0.0700\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0749\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nIn the above code:\\n\\nThe model is trained on the normalized stock price data for 20 epochs with a batch size of 32.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "'''\n",
    "In the above code:\n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\\nIn the above code:\\n\\nThe model's predictions are transformed back to the original scale using the inverse transform of the scaler.\\n\\nThe true data and predictions are plotted to visualize the model's performance.\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(data, label='True Data')\n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''\n",
    "In the above code:\n",
    "\n",
    "The model's predictions are transformed back to the original scale using the inverse transform of the scaler.\n",
    "\n",
    "The true data and predictions are plotted to visualize the model's performance.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So theoretically, I can compile my own transformer engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1: Add dropout to the Transformer model\n",
    "Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Add a dropout layer after the Flatten layer in the model.\n",
    "\n",
    "Set the dropout rate to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - loss: 5.8667\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 1.1551\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.4676\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.2486\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.1704\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.1332\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.1216\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.1113\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.1042\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.0998\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.0956\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.0435\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.0264\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.0284\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.0290\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0221\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 0.0155\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.0152\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 0.0154\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 0.0124\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.7722e-04\n",
      "Test loss: 0.0008909317548386753\n"
     ]
    }
   ],
   "source": [
    "from keras.api.layers import Dropout\n",
    "import keras\n",
    "\n",
    "# Add a dropout layer after the Flatten layer\n",
    "flatten = keras.layers.Flatten()(encoder_outputs)\n",
    "dropout = Dropout(0.5)(flatten)\n",
    "outputs = keras.layers.Dense(1)(dropout)\n",
    "\n",
    "# Build the model\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2: Experiment with different batch sizes\n",
    "Objective: Observe the impact of different batch sizes on model performance.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Train the model with a batch size of 16.\n",
    "\n",
    "Train the model with a batch size of 64.\n",
    "\n",
    "Compare the training time and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - loss: 0.0155\n",
      "Epoch 2/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0319\n",
      "Epoch 3/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0288\n",
      "Epoch 4/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0308\n",
      "Epoch 5/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0250\n",
      "Epoch 6/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0339\n",
      "Epoch 7/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0250\n",
      "Epoch 8/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0170\n",
      "Epoch 9/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - loss: 0.0233\n",
      "Epoch 10/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0269\n",
      "Epoch 11/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0207\n",
      "Epoch 12/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0188\n",
      "Epoch 13/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.0316\n",
      "Epoch 14/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - loss: 0.0197\n",
      "Epoch 15/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - loss: 0.0190\n",
      "Epoch 16/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.0114\n",
      "Epoch 17/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.0139\n",
      "Epoch 18/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0123\n",
      "Epoch 19/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0122\n",
      "Epoch 20/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.0091\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013\n",
      "Test loss with batch size 16: 0.0009177840547636151\n",
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0096\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0049\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0036\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0037\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0033\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0033\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0033\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0029\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0034\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0052\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0036\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0030\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0026\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0032\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0029\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0028\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0030\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0029\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0057\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0027\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.9175e-04\n",
      "Test loss with batch size 64: 0.0004038810438942164\n"
     ]
    }
   ],
   "source": [
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3: Use a different activation function\n",
    "Objective: Understand how different activation functions impact the model performance.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Change the activation function of the Dense layer to tanh.\n",
    "\n",
    "Train and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 68ms/step - loss: 0.2937\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.2566\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 0.3418\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.2931\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.2886\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.2991\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.2956\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.2922\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.2991\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 0.3043\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 0.3015\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 0.2909\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.2997\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.2988\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.3006\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.2933\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.2849\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.3011\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.2986\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.2975\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.5205\n",
      "Test loss with tanh activation: 0.29668867588043213\n"
     ]
    }
   ],
   "source": [
    "# Change the activation function of the Dense layer to 'tanh'\n",
    "outputs = keras.layers.Dense(1, activation='tanh')(dropout)\n",
    "\n",
    "# Build the model\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I think this is an important part of learning tensorflow which can help me understand tensorflow deeper.\n",
    "# I will review this part later\n",
    "# PS: I read <Attention is all you need> on the way to school this morning. I was a little bit confused. I should read it more times and figure it out clearly.\n",
    "# https://research.google/pubs/attention-is-all-you-need/\n",
    "# and some blog about running tensorflow on Apple Silicon's GPU\n",
    "# https://twm.me/posts/how-to-run-tensorflow-gpu-mac/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
